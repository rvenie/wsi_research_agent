# ResearchHub Agent System MVP

## 1. Цели и предпосылки

### 1.1. Зачем идем в разработку продукта?

**Бизнес-цель (Product Owner):**
Создать интеллектуальную агентную систему ResearchHub, которая автоматизирует комплексный анализ научных публикаций в области медицинских мультимодальных моделей, отслеживает появление новых данных, метрик и технологий в сфере цифровой патологии, обеспечивая компании конкурентное преимущество через непрерывный мониторинг научного ландшафта.

**Почему станет лучше, чем сейчас, от использования ML (Product Owner & Data Scientist):**
- **Проактивная аналитика:** Система самостоятельно выявляет новые тренды и breakthrough решения в новых медицинских моделях 
- **Конкурентная разведка:** Автоматическое отслеживание метрик конкурентов (Paige, Owkin, Mahmood Lab, PathAI, etc.) и их новых публикаций с извлечением ключевых показателей
- **Динамический мониторинг:** Отслеживание публикаций на предмет появления исходного кода, WSI датасетов в данных, версионирование изменений
- **Контекстная экспертиза:** Система понимает специфику медицинских метрик (HER2, Nottingham grade, ER/PR, Ki-67) и может оценивать научную значимость
- **Автоматическое обогащение:** Извлечение новых ключевых слов, локаций публикаций, методологий для расширения поисковых возможностей

**Что будем считать успехом итерации с точки зрения бизнеса (Product Owner):**
- Выявление минимум 5 важных публикаций с извлеченными метриками
- Автоматическое обнаружение появления исходного кода, данных или новых версий для 3+ ранее отслеживаемых статей
- Формирование еженедельных сводок по динамике развития медицинских моделей и выявления новых открытых датасетов WSI
- Сокращение времени аналитиков на мониторинг научного ландшафта на 80%

### 1.2. Бизнес-требования и ограничения

**Краткое описание БТ и ссылки на детальные документы с бизнес-требованиями (Product Owner):**
Система должна функционировать как сеть специализированных агентов, каждый из которых отвечает за определенный аспект научной аналитики: поиск публикаций, оценку значимости, мониторинг данных, анализ конкурентов и экстракцию метрик. Все агенты работают согласованно, обмениваясь информацией и обогащая общую базу знаний.

**Бизнес-ограничения (Product Owner):**
- Работа с публичными источниками: arXiv, Zenodo, HuggingFace, PubMed, Nature, Science, медицинские журналы
- Соблюдение rate limits API различных платформ и copyright ограничений
- Этические ограничения при работе с медицинскими данными и исследованиями
- Бюджет на API calls для GPT/Claude моделей для анализа контента

**Что мы ожидаем от конкретной итерации (Product Owner):**
- **Целевые источники для мониторинга:**
  - **Компании-конкуренты:** Paige AI, Owkin, PathAI, Proscia
  - **Исследовательские группы:** Mahmood Lab (Harvard), Stanford HAI, MIT CSAIL
  - **Ключевые конференции:** MICCAI, ISBI, MIDL, NeurIPS (medical track)
  - **Журналы:** Nature Medicine, Science Translational Medicine, Medical Image Analysis

**Описание бизнес-процесса пилота (Product Owner):**
- R&D команды получают еженедельные сгенерированные дайджесты с ключевыми открытиями
- Product managers используют инсайты из дайджестов для корректировки роадмапа и приоритизации разработки фичей
- Команда по развитию бизнеса заранее узнаёт о новых возможностях на рынке

**Что считаем успешным пилотом (Product Owner):**
- Автоматическое выявление 90%+ значимых публикаций в области цифровой патологии за неделю
- Точность извлечения метрик из статей >95%
- Время отклика системы на новые публикации <24 часа
- Выработка действенных выводов для R&D с измеримым влиянием на принятие решений по продукту

### 1.3. Что входит в скоуп проекта/итерации, что не входит

**На закрытие каких БТ подписываемся в данной итерации (Data Scientist):**

**Агент поиска и мониторинга публикаций:**
- Автоматический поиск по расширенным ключевым словам: мультимодальные модели, digital pathology, foundation models, HER2, Nottingham grading, etc.
- RSS и API мониторинг arXiv, PubMed, журналов с мгновенными уведомлениями
- Версионирование публикаций (v1, v2, final) с отслеживанием изменений

**Агент оценки научной значимости:**
- LLM-based анализ разделовabstract и introduction для оценки новизны и потенциального влияния на сферу
- Классификация по релевантности к задачам компании (high/medium/low priority)
- Экстракция основных вкладов и методологических новшеств

**Агент мониторинга данных, метрик и кода:**
- Отслеживание публикаций на предмет появления WSI датсетов в  GitHub, HuggingFace, Zenodo, etc.
- Автоматическое обнаружение ссылок на Hugging Face, Papers with Code
- Мониторинг обновлений существующих репозиториев
- Автоматическое извлечение метрик производительности моделей

**Агент медицинских метрик:**
- Специализированная экстракция медицинских метрик: HER2 (0/1+/2+/3+), Nottingham grade, ER/PR/Ki-67
- Понимание контекста и валидация корректности извлеченных значений
- Сравнение метрик между исследованиями и временными периодами

**Что не будет закрыто (Data Scientist):**
- Полнотекстовый анализ платных статей (только abstract и preview)
- Автоматический анализ изображений из публикаций
- Интеграция с внутренними экспериментальными данными компании
- Предиктивная аналитика трендов (только дескриптивная)

**Описание результата с точки зрения качества кода и воспроизводимости решения (Data Scientist):**
- Модульная агентная архитектура с четким разделением ответственности
- Docker-контейнеризация каждого агента для независимого развертывания
- Полное логирование и мониторинг всех компонентов системы

**Описание планируемого технического долга (Data Scientist):**
- Ограниченная отказоусточивость между агентами
- Базовая система приоритизации задач 
- Упрощённая схема базы знаний
- Ручная настройка гиперпараметров для промптов LLM (автоматическая оптимизация промптов — в будущем).

### 1.4. Предпосылки решения

**Описание всех общих предпосылок решения (Data Scientist):**

**Архитектурные предпосылки:**
Система построена на агентной архитектуре, где каждый агент является автономным компонентом с собственной специализацией, но способным к кооперации через общую шину сообщений и централизованную базу знаний.

**Данные и сущности:**
- **Блоки данных:** научные публикации, метаданные авторов, метрики производительности, репозитории кода, wsi датасеты и метаданные
- **Горизонт прогноза:** Real-time мониторинг + еженедельные аналитические отчеты
- **Гранулярность модели:** Индивидуальные статьи, авторские кластеры, конкурентные компании, тематические направления
- **Частота обновления:** раз в сутки

**Технические предпосылки:**
- **База знаний:** Векторная база данных (Weaviate) для semantic search по 15K+ статей в год
- **Коммуникация агентов:** Event-driven архитектура с Redis для межагентного взаимодействия
- **LLM интеграция:** GPT-5/Claude/Mistral для анализа контента и извлечения insights (~1000 API calls/day budget)
- **Temporal processing:** Dagster для оркестрации периодических задач
- **Monitoring:** система мониторинга состояния агентов и качества их работы

**Источники данных:**
- arXiv API, PubMed API, CrossRef API (публичные, rate-limited)
- RSS feeds ведущих журналов и конференций
- GitHub API, Hugging Face API, Papers with Code API, Zenodo API
- Google Scholar (scraping с соблюдением ToS)

## 2. Методология

### 2.1. Постановка задачи

**Что делаем с технической точки зрения (Data Scientist):**
Разрабатываем мультиагентную систему научной аналитики, которая работает как "умный исследовательский ассистент". Система включает:

1. **Поиск и классификация:** автоматическое обнаружение релевантных публикаций 
2. **Scoring и ранжирование:** LLM-based оценка научной значимости
3. **Information extraction:** структурированное извлечение медицинских метрик и данных
4. **Anomaly detection:** выявление выдающихся публикаций и конкурентных угроз
5. **Knowledge synthesis:** агрегация инсайтов для формирования рекомендаций к действию

**Специализированные агенты:**
- **Discovery Agent** - поиск и мониторинг (NLP + интеграции API)
- **Significance Agent** - оценка научного влияния (LLM + традиционное ML)
- **Data Tracker Agent** - мониторинг доступности кода/WSI датасетов (веб-скрапинг + API)
- **Competitor Intelligence Agent** - конкурентный анализ (NER + извлечение знаний)
- **Medical Metrics Agent** - извлечение специализированных медицинских знаний (доменно-специфичный NLP)
- **Synthesis Agent** - агрегация инсайтов и отчетность (мультимодальный синтез)

### 2.2. Блок-схема решения

**Агентная архитектура ResearchHub (MVP vs Baseline):**

**Baseline (текущий процесс):**
```
[Ручной поиск] → [Ручная проверка] → [Ручной анализ] → [Еженедельные отчеты]
     ↓                 ↓                  ↓                   ↓
• Google Scholar   • Чтение экспертом   • Электронные     • PowerPoint
• Ручные алерты   • Ручная оценка      таблицы          • Email рассылка
• ~40ч/неделю     • Непоследовательно  • Подвержено      • Задержанные
                                       ошибкам           инсайты
```

**MVP  (ResearchHub):**
**MVP (Система AgentHub):**
```
                           ┌─────────────────┐
                           │  Центральный    │
                           │      Хаб        │
                           │  (Weaviate +    │
                           │   Redis +       │
                           │ Оркестратор)    │
                           └─────────────────┘
                                   │
            ┌──────────────────────┼──────────────────────┐
            │                      │                      │
    ┌───────▼────────┐    ┌───────▼────────┐    ┌───────▼────────┐
    │ Discovery      │    │ Significance   │    │ WSI Data       │
    │ Agent          │    │ Agent          │    │ Agent          │
    │ • arXiv API    │    │ • LLM анализ   │    │ • WSI форматы  │
    │ • PubMed API   │    │ • Оценка       │    │ • TCIA, Zenodo │
    │ • RSS ленты    │    │   влияния      │    │ • Метаданные   │
    │ • WSI-поиск    │    │                │    │                │
    └────────┬───────┘    └────────────────┘    └────────▲───────┘
             │                     │                     │
             │ WSI упоминания     │                     │
             └─────────────────────┼─────────────────────┘
                                   │
            ┌──────────────────────┼──────────────────────┐
            │                      │                      │
    ┌───────▼────────┐    ┌───────▼────────┐    ┌───────▼────────┐
    │ Competitor     │    │ Medical        │    │ Synthesis      │
    │ Intelligence   │    │ Metrics        │    │ Agent          │
    │ • Мониторинг   │    │ • HER2/Grade   │    │ • Отчеты       │
    │   Paige        │    │ • WSI метрики  │    │ • Алерты       │
    │ • Трекинг      │    │ • Окрашивание  │    │ • Дашборд      │
    │   Owkin        │    │ • Ткани        │    │ • Сравнение    │
    └────────────────┘    └────────────────┘    └────────────────┘
```

### 2.3. Этапы решения задачи

**Этап 1 - Подготовка данных и Discovery Agent (Поиск и мониторинг)**

**Данные и сущности для целевых переменных:**

| Целевая переменная | Тип | Описание | Возможные значения | Источник ground truth |
|-------------------|-----|----------|-------------------|---------------------|
| `is_relevant` | binary | Релевантность для компании | 0/1 | Expert validation |
| `significance_score` | continuous | Научная значимость | 0.0-10.0 | LLM + expert consensus |
| `business_priority` | ordinal | Бизнес-приоритет | P1/P2/P3 | Product owner input |
| `competitive_threat` | ordinal | Конкурентная угроза | LOW/MEDIUM/HIGH | Competitive analysis |
| `medical_relevance` | continuous | Медицинская релевантность | 0.0-10.0 | Medical expert review |

**Данные и сущности для признаков:**

| Название данных | Есть ли данные в компании | Требуемый ресурс для получения | Проверено ли качество |
|----------------|--------------------------|------------------------------|---------------------|
| arXiv publications | Нет, внешний API | DS для API integration | Требует валидации |
| PubMed metadata | Нет, внешний API | DS для parsing | Требует валидации |
| Author h-index | Нет, Google Scholar API | DS + potential legal review | Нет |
| Journal impact factors | Нет, JCR database | DS + possible subscription | Нет |
| GitHub repositories | Нет, GitHub API | DS для API integration | Требует валидации |
| Competitor publications | Частично есть в мониторинге | DS для автоматизации | Частично |
| Medical metrics ground truth | Нет | Medical expert + DS | Критически важно |

**Ключевые признаки Discovery Agent:**
| Признак | Тип | Описание | Пример значения | Важность |
|---------|-----|----------|----------------|----------|
| `title` | str | Заголовок статьи | "Multimodal AI for breast cancer diagnosis" | HIGH |
| `abstract` | str | Аннотация (0-2000 символов) | "We present a novel approach..." | HIGH |
| `authors` | list[str] | Список авторов | ["Smith, J.", "Doe, A."] | MEDIUM |
| `publication_date` | datetime | Дата публикации | 2024-01-15 | HIGH |
| `journal_name` | str | Название журнала | "Nature Medicine" | HIGH |
| `keywords` | list[str] | Ключевые слова | ["WSI", "pathology", "AI"] | HIGH |
| `citation_count` | int | Количество цитирований | 42 | MEDIUM |

**Для бейзлайна (ручной процесс):**
- **Формирование выборки:** Manual Google Scholar searches 2-3 раза в неделю по ключевым словам
- **Горизонт:** Ad-hoc поиск без систематического мониторинга
- **Гранулярность:** Отдельные статьи, найденные случайным образом
- **Частота пересчета:** Нет систематической частоты, по необходимости
- **Целевая переменная:** Subjective relevance judgment экспертом
- **Метрики качества:** Нет формальных метрик, основано на экспертном мнении
- **Техника решения:** 
  - Ручной поиск по ключевым словам в Google Scholar, PubMed
  - Получение рассылок на имеил
  - Excel spreadsheet для tracking (~50-100 papers)
- **Ожидаемый результат:** 5-10 статей в неделю, высокая вероятность пропуска важных публикаций
- **Риски:** Пропуск важных статей, субъективность оценок

**Для MVP:**
- **Источники мониторинга:** 
  - arXiv API: категории cs.CV, cs.LG, q-bio (ежедневно)
  - PubMed API: медицинские термины (еженедельно)
  - RSS ленты: Nature Medicine, Science Translational Medicine
  - WSI-специфичные: TCIA, PathPresenter, Cancer Digital Slide Archive
  - Алерты по целевым авторам и компаниям
  - Блоги конкурентов
- **Горизонт:** Ежесуточный мониторинг + архив за 6 месяцев
- **Гранулярность:** Отдельные статьи, авторов, организации, датасеты
- **Частота обновления:** Каждые 6 часов для приоритетных источников
- **Целевые метрики:**
  - Полнота покрытия ≥ 90% релевантных публикаций
  - Задержка обработки < 24 часа
  - Доля ложных срабатываний < 20%
  - Время работы системы ≥ 99%
- **Техника решения:**
  - Интеграция с API (1000 запросов/час)
  - Семантический поиск через SciBERT
  - Фильтрация по ключевым словам и журналам
  - **WSI-связка:** 
    - NLP анализ секций "Data Availability", "Supplementary Materials", "Code and Data"
    - Поиск паттернов: zenodo.org/*, figshare.com/*, github.com/*/data, tcia.at/*
    - Извлечение упоминаний форматов: .svs, .tiff, .ndpi, .mrxs, "whole slide", "digital slide"
    - Обнаружение фраз: "publicly available", "upon request", "supplementary dataset"
  - **Cross-reference:** автоматическая передача найденных WSI упоминаний в WSI Data Agent с метаданными статьи
  - Удаление дубликатов по заголовкам и DOI
  - Потоковая обработка через Kafka + кэш Redis
- **Ожидаемый результат:** 50-100 релевантных статей в неделю с метаданными, оценками релевантности и флагами наличия WSI данных

**Краткое описание результата этапа:**
- **Knowledge Base:**  БД статей со структурированными метаданными
- **Discovery Pipeline:** Автоматизированный сбор 5-10 релевантных статей/неделю
- **Источники:** Интеграции с arXiv, PubMed, CrossRef с proper rate limiting

**Этап 2 - WSI Data Agent (Поиск и анализ WSI данных)**

**Для бейзлайна (ручной процесс):**
- **Горизонт:** Эпизодический поиск WSI датасетов в статьях
- **Гранулярность:** Поверхностный анализ доступности без технических деталей
- **Частота пересчета:** По запросу, нет систематического мониторинга
- **Целевые переменные:** Простые списки найденных датасетов
- **Метрики качества:** Нет формальных метрик качества данных
- **Техника решения:**
  - Поиск в Google по названиям форматов
  - Ручной просмотр описаний датасетов
  - Субъективная оценка релевантности
- **Необходимый результат:** Неструктурированный список потенциальных датасетов
- **Риски:** Пропуск новых коллекций, неполная техническая характеристика, дублирование работы

**Для MVP:**
- **Горизонт:** Непрерывный мониторинг всех WSI репозиториев + анализ статей от Discovery Agent + исторический анализ за 2 года
- **Гранулярность:** Полная техническая характеризация каждого датасета + связь со статьями + сравнение с внутренними коллекциями
- **Частота пересчета:** Ежедневное сканирование + real-time обработка WSI упоминаний из статей
- **Целевые переменные:**
  - `wsi_format`: Многоклассовая (.svs, .tiff, .ndpi, .mrxs, .vsi, .png)
  - `magnification_levels`: Список доступных увеличений (10x, 20x, 40x)
  - `tissue_type`: Тип ткани (breast, lung, prostate, colon, skin)
  - `staining_protocol`: Протокол окрашивания (H&E, IHC, IF, FISH)
  - `dataset_size`: Количество слайдов в коллекции
  - `annotation_quality`: Качество разметки (expert, resident, algorithmic)
  - `source_paper_doi`: DOI статьи, с которой связан датасет
  - `data_availability_status`: Статус доступности (public, upon_request, restricted)
  - `publication_recency`: Время между публикацией статьи и обнаружением данных
- **Метрики качества:**
  - Полнота технических метаданных ≥ 85%
  - Точность извлечения характеристик ≥ 90%
  - Обнаружение дубликатов с внутренними данными ≥ 95%
- **Техника решения:**
  - Автоматическое сканирование TCIA, Zenodo, Figshare APIs
  - **Cross-agent интеграция:** 
    - Получение WSI сигналов от Discovery Agent с контекстом статьи
    - Приоритизация статей с высокими significance scores для глубокого анализа данных
  - **Deep text analysis:** 
    - Регулярные выражения для URL паттернов: `(zenodo|figshare|github)\.org/[^\s]+`
    - Named Entity Recognition для извлечения названий датасетов
    - Парсинг таблиц с характеристиками данных (размер, формат, аннотации)
  - **URL extraction и валидация:**
    - Автоматическая проверка доступности найденных ссылок
    - Извлечение метаданных из repository APIs (Zenodo, Figshare)
    - Классификация доступности: "public", "upon_request", "restricted"
  - Парсинг DICOM/OME-TIFF заголовков для технических характеристик
  - NLP для извлечения клинических данных из описаний
  - Алгоритмы сравнения с внутренними коллекциями компании
  - Computer vision для анализа preview изображений
- **Необходимый результат:** Структурированный каталог WSI датасетов с прямыми ссылками на источники статей, gap analysis и рекомендациями по приоритизации
- **Риски:** Сложность парсинга медицинских метаданных, вариативность форматов, лицензионные ограничения

**Этап 3 - Significance Agent (Оценка значимости)**

**Для бейзлайна (ручной процесс):**
- **Формирование выборки:** Субъективная оценка экспертом на основе title/abstract
- **Горизонт:** Оценка по мере поступления статей без систематичности
- **Гранулярность:** Простая категоризация: важная/неважная
- **Частота пересчета:** Нет, однократная оценка при первом просмотре
- **Целевая переменная:** Субъективная важность (высокая/средняя/низкая)
- **Метрики качества:** Нет формальных метрик, единство между экспертами низкое
- **Техника решения:**
  - Чтение и субьективная оценка репутации авторов
  - Безоценочная и формальная приоритезация по чтению новых статей
  - Рассылка статей и получение статей от коллег
- **Необходимый результат:** Список статей с оценками субьективной оценкой важности
- **Риски:** Высокая субъективность, неравные приоритеты, пропуск важных статей

**Для MVP:**
- **Горизонт:** Систематическая оценка всех релевантных статей
- **Гранулярность:** Детальная оценка + структурированное обоснование + оценка влияния на бизнес
- **Частота пересчета:** Оценка в реальном времени при обнаружении новых статей
- **Целевая переменная:** 
  - `significance_score`: Непрерывная оценка научного влияния (0.0-10.0)
  - `business_priority`: Порядковая (P1: прорыв, P2: важная, P3: стандартная)
- **Метрики качества:**
  - Корреляция с экспертными оценками ≥ 0.85 (Пирсон)
  - Точность классификации ≥ 75% для уровней приоритета (P1/P2/P3)
  - Смещение < 0.5 между различными областями исследований
- **Техника решения:**
  - Анализ через LLM: GPT-5 со структурированными промптами для оценки новизны
  - Инженерия признаков: репутация авторов, импакт-фактор журнала, индикаторы методологических новшеств
  - Ансамблевый подход: LLM оценки + традиционное ML на структурированных признаках
  - Калибровка: масштабирование Платта для калибровки вероятностей
- **Необходимый результат:** Ранжированный список статей с обоснованными оценками значимости и автоматическое выделение статей P1
- **Риски:** Стоимость LLM API, потенциальное смещение в оценках, необходимость непрерывной калибровки

**Этап 4 - Medical Metrics Agent (Специализированная экстракция)**

**Для бейзлайна (ручной процесс):**
- **Горизонт:** Эпизодическое извлечение при обнаружении релевантной статьи
- **Гранулярность:** Базовое извлечение метрик без систематической структуры
- **Частота пересчета:** Нет, однократное извлечение при первом чтении
- **Целевые переменные:** Неформальные заметки о медицинских результатах
- **Метрики качества:** Нет валидации, потенциальные ошибки извлечения
- **Техника решения:**
  - Ручное чтение + копирование в Excel
  - Неформальные заметки без стандартизации
  - Нет валидации против медицинских онтологий
- **Необходимый результат:** Неструктурированная коллекция медицинских данных
- **Риски:** Ошибки извлечения, пропуск метрик, непоследовательный формат, отсутствие контроля качества

**Для MVP:**
- **Горизонт:** Систематическое извлечение всех медицинских метрик из релевантных статей
- **Гранулярность:** Структурированное извлечение с оценками уверенности и контекстом
- **Частота пересчета:** Автоматическое переизвлечение при обновлении статей или улучшении алгоритмов
- **Целевые переменные:**
  - `her2_status`: Многоклассовая (0/1+/2+/3+/FISH+/FISH-)
  - `nottingham_grade`: Структурированное извлечение (tubular/nuclear/mitotic оценки)  
  - `hormone_receptors`: Непрерывное извлечение (ER%, PR%, Ki-67%)
  - `wsi_performance_metrics`: WSI-специфичные метрики (CAMELYON AUC, TCGA accuracy)
  - `tissue_characteristics`: Характеристики ткани (размер среза, толщина, подготовка)
  - `image_resolution`: Технические характеристики (микроны/пиксель, размеры файла)
- **Метрики качества:**
  - Точность извлечения ≥ 90% на медицинских метриках
  - Валидация медицинских знаний ≥ 95% (согласованность с клиническими рекомендациями)
  - Калибровка уверенности: высокоуверенные предсказания должны быть более точными
- **Техника решения:**
  - Медицинский NLP: BioBERT + ClinicalBERT для понимания медицинской специфики
  - Графы знаний: интеграция с медицинскими онтологиями (SNOMED, ICD, ICD-O)
  - Правила валидации: проверка диапазонов + проверка клинической согласованности
  - Эксперт в цикле: отметка подозрительных извлечений для ручной проверки
- **Необходимый результат:** Структурированная база медицинских знаний с валидированными извлечениями
- **Риски:** Сложность медицинской области, необходимость экспертной валидации, потенциальные регуляторные вопросы

**Этап 5 - Competitor Intelligence Agent**

**Для бейзлайна (ручной процесс):**
- **Горизонт:** Реактивный мониторинг, часто пропускающий ранние исследования  
- **Гранулярность:** Упоминания компаний на высоком уровне без детального анализа
- **Частота пересчета:** Нерегулярная, часто после публичных объявлений
- **Целевые переменные:** Неформальные заметки о конкурентах
- **Метрики качества:** Нет систематических метрик, высокий шанс пропуска угроз
- **Техника решения:**
  - Ручные Google-алерты с базовыми ключевыми словами
  - Чтение пресс-релизов конкурентов и публичных материалов
  - Неформальные обсуждения с отраслевыми контактами
- **Необходимый результат:** Разовые отчеты по конкурентной разведке
- **Риски:** Позднее обнаружение, пропуск ранних исследовательских сигналов, неполное покрытие

**Для MVP:**  
- **Горизонт:** Проактивный мониторинг цикла исследования→продукт конкурентов
- **Гранулярность:** Детальный анализ технологий + оценка влияния на бизнес
- **Частота пересчета:** Мониторинг в реальном времени + еженедельные брифинги по конкурентам
- **Целевые переменные:**
  - `competitive_threat_level`: Порядковая (НИЗКАЯ/СРЕДНЯЯ/ВЫСОКАЯ/КРИТИЧЕСКАЯ)
  - `time_to_market_estimate`: Непрерывная (6-36 месяцев)
  - `technology_advancement_score`: Непрерывная (0-10)
- **Метрики качества:**
  - Точность обнаружения угроз ≥ 90% (избегать ложных тревог)
  - Полнота покрытия ≥ 85% известных публикаций конкурентов
  - Время опережения ≥ 2 недель раньше публичной осведомленности
- **Техника решения:**
  - Распознавание именованных сущностей для выявления продуктов и технологий
  - Извлечение метрик производительности из таблиц и графиков
  - Анализ временных линий для предсказания следующих шагов
  - Сетевой анализ авторов и коллабораций
- **Необходимый результат:** Проактивная конкурентная разведка с системой раннего предупреждения
- **Риски:** Ответная реакция конкурентов, необходимость соблюдения этических границ, валидация качества информации

**Этап 6 - Synthesis Agent (Агрегация и отчеты)**

**Для бейзлайна (ручной процесс):**
- **Горизонт:** Ежемесячные или квартальные неформальные сводки
- **Гранулярность:** Пункты высокого уровня без детального анализа
- **Частота пересчета:** Нерегулярная отчетность, часто по запросу руководства  
- **Целевые переменные:** Базовые сводные отчеты
- **Метрики качества:** Нет метрик применимости, субъективная оценка качества
- **Техника решения:**
  - PowerPoint презентации с ручным созданием графиков
  - Email сводки с ограниченным распространением
  - Разовые инсайты без систематического анализа
- **Необходимый результат:** Неформальные обновления исследований
- **Риски:** Задержанные инсайты, пропущенные связи, ограниченное распространение, отсутствие практических рекомендаций

**Для MVP:**
- **Горизонт:** Синтез в реальном времени + структурированная периодическая отчетность
- **Гранулярность:** Многоуровневые инсайты: тактические алерты + стратегические тренды + практические рекомендации
- **Частота пересчета:** Непрерывная агрегация + запланированная генерация отчетов
- **Целевые переменные:**
  - Еженедельный дайджест исследований: топ-10 наиболее значимых разработок
  - Конкурентные алерты: КРИТИЧЕСКИЕ угрозы, требующие немедленного внимания  
  - Анализ трендов: развивающиеся исследовательские направления с бизнес-последствиями
  - WSI датасет рекомендации: новые коллекции с gap analysis относительно внутренних данных
- **Метрики качества:**
  - Оценка применимости ≥ 8/10 от владельцев продукта
  - Точность алертов ≥ 95% для КРИТИЧЕСКИХ уведомлений
  - Время до инсайта < 48 часов от оригинальной публикации
- **Техника решения:**
  - Мультимодальный синтез: текст + графики + интерактивные дашборды
  - Маршрутизация по приоритетам: разные заинтересованные стороны получают целевые инсайты
  - Автоматическая генерация отчетов с резюме на естественном языке
  - Интеграция с инструментами бизнес-планирования для практических рекомендаций
- **Необходимый результат:** Комплексная платформа исследовательской аналитики с инсайтами в реальном времени
- **Предусмотрена бизнес-проверка результата:**
  - Еженедельные обзорные сессии с руководством R&D для обратной связи по качеству инсайтов
  - Ежемесячные брифинги по конкурентной разведке для стратегического планирования
  - Квартальная оценка влияния на решения по дорожной карте продукта
  - Ежемесячная валидация WSI рекомендаций с Data Engineering командой
